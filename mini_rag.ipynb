{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e25d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axel\\anaconda3\\envs\\mini_rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import Ollama  # Solution locale\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66927c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chunks créés : 13\n"
     ]
    }
   ],
   "source": [
    "# 1. Charger vos documents\n",
    "loader = PyPDFLoader(\"TP8_cnn.pdf\")  # ou TextLoader, DirectoryLoader\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Découper en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # taille des chunks\n",
    "    chunk_overlap=200,    # chevauchement pour garder le contexte\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Nombre de chunks créés : {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf5ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base FAISS créée et sauvegardée !\n"
     ]
    }
   ],
   "source": [
    "# 1. Choisir le modèle d'embedding\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cpu'}  # 'cuda' si GPU\n",
    ")\n",
    "\n",
    "# 2. Créer la base vectorielle FAISS\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# 3. Sauvegarder la base\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "print(\"Base FAISS créée et sauvegardée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4dabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21df1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"mistral\",\n",
    "    temperature=0.1,  # Pour des réponses plus factuelles\n",
    "    num_predict=512   # Limite la longueur des réponses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318ad196",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671e84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The motivation of TP8 (Deep Learning and Convolutional Neural Networks) is to implement a variant of neural networks that are particularly useful for image processing. This variant, known as CNN (Convolutional Neural Network), will be learned, used, and analyzed. However, the focus will be on an Arduino DUE which has less computing power compared to computers.\n"
     ]
    }
   ],
   "source": [
    "question = \"Quelle est la motivation du TP8 Deep Learning et Réseau de Neurones Convolutionnel ?\"\n",
    "response = qa_chain.run(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855e435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
