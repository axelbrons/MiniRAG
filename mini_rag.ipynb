{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e25d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import Ollama  # Solution locale\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import gradio as gr\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm as notebook_tqdm\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66927c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chunks créés : 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_files = [\"cv_fr.pdf\", \"Valentin_Kocijancic_CV_2025 .pdf\"]\n",
    "\n",
    "# chargement pdf\n",
    "documents = []\n",
    "for file in pdf_files:\n",
    "    loader = PyPDFLoader(file)\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n",
    "\n",
    "# chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # taille des chunks\n",
    "    chunk_overlap=200,    # chevauchement pour garder le contexte\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Nombre de chunks créés : {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dbf5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choisir le modèle d'embedding\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}  # 'cuda' si GPU\n",
    ")\n",
    "\n",
    "# 2. Créer la base vectorielle FAISS\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# 3. Sauvegarder la base\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "#vector_store = FAISS.load_local(\"faiss_index\", embedding_model,allow_dangerous_deserialization=True)\n",
    "\n",
    "#print(\"Base FAISS créée et sauvegardée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce4dabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21df1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"phi3\",\n",
    "    temperature=0.1,  # Pour des réponses plus factuelles\n",
    "    num_predict=256   # Limite la longueur des réponses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63b495f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Tu es un assistant intelligent spécialisé dans l'analyse de CV pour les recruteurs.\n",
    "Tu dois répondre **en français** de manière claire, concise et professionnelle.\n",
    "\n",
    "Tu disposes des informations suivantes issues d'une base de CV :\n",
    "{context}\n",
    "\n",
    "Consignes :\n",
    "- Utilise uniquement les informations présentes dans le contexte pour répondre.\n",
    "- Si la réponse n'est pas clairement indiquée, dis simplement : \"L'information n'est pas disponible dans les CV.\"\n",
    "- Si plusieurs candidats semblent correspondre, mentionne leurs prénoms et explique brièvement pourquoi.\n",
    "- Si un candidat se démarque particulièrement, indique-le clairement et justifie ton choix.\n",
    "- Ne traduis pas les noms de postes ou d’entreprises.\n",
    "\n",
    "Question du recruteur : {question}\n",
    "\n",
    "Réponse :\n",
    "\"\"\"\n",
    "\n",
    "prompt_fr = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fb762f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_fr}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "671e84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse :  Le candidat Axel Bröns possède une expérience remarquable dans le développement d'algorithmes. Il a effectué un stage en algorithmique et modélisation quantitative à L’Immobiliere De Réseau où il a conçu, implémenté et testé environ 20 stratégies de trading algorithmique sur cTrader en C#. Il a également optimisé les hyperparamètres des stratégies via cAlgo et PineScript, visant un facteur de profit supérieur à 2,5. En outre, il a modélisé mathématiquement le risque et le rendement à l'aide du critère de Kelly. Ces expériences démontrent une solide compétence en développement d'algorithmes.\n",
      "Source : langages (RoBERTa, BERT) (en cours)\n",
      "A PROPOS DE MOI\n",
      "Étudiant (bac +4) en école d’ingénieurs,\n",
      "passionné par l’intelligence artiﬁcielle, la data\n",
      "et la recherche. Curieux et rigoureux, je\n",
      "recherche un stage de 4 mois minimum à\n",
      "partir du 13 avril 2026 à Paris ou Lyon.\n",
      "FORMATIONS\n",
      "Diplôme d’ingénieurs\n",
      "École centrale d’électronique - ECE\n",
      "Ὄ52022 – 2027 ♂¶ap-¶arkerParis, France\n",
      "• Majeure Data & IA\n",
      "• Mineure Recherche & Développement\n",
      "• Major de promotion de la première année\n",
      "(1er / 135)\n",
      "• Vice-président de l’association Tutorat\n",
      "Lyon\n",
      "Semestre à l’étranger\n",
      "Hanyang University\n",
      "Ὄ5Sept - Déc 2024 ♂¶ap-¶arkerSéoul, Corée du Sud\n",
      "• GPA : 95 / 100\n",
      "COMPÉTENCES\n",
      "C++ / C Python SQL Java\n",
      "Scikit-learn TensorFlow PyTorch\n",
      "Huggingface Matplotlib NumPy\n",
      "Pandas Seaborn\n",
      "Power BI LATEX Jupyter Arduino\n",
      "Excel\n",
      "LANGAGES\n",
      "Français Natif\n",
      "Anglais C1\n",
      "Espagnol A2\n",
      "Coréen A1\n"
     ]
    }
   ],
   "source": [
    "question = \"Quel candidat possède la meilleur expérience pour le développement d'algorithmes ?\"\n",
    "response = qa_chain({\"query\" : question}, return_only_outputs=False)\n",
    "print(\"Réponse :\", response[\"result\"])\n",
    "print(\"Source :\", response[\"source_documents\"][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7855e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valentin Kocijančić est le candidat qui recherche un stage en finance, comme indiqué dans son CV où il mentionne explicitement qu'il \"souhaite appliquer mes compétences techniques et mon esprit analytique au sein d’une équipe dynamique et stimulante.\" Il cherche également à commencer le stage dès le 13 avril 2026, ce qui correspond aux dates mentionnées dans la question du recruteur.\n"
     ]
    }
   ],
   "source": [
    "question = \"Quel candidat cherche un stage en finance ?\"\n",
    "response = qa_chain({\"query\" : question})\n",
    "print(response['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
