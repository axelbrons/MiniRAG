{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Axel\\anaconda3\\envs\\mini_rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import Ollama  # Solution locale\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm as notebook_tqdm\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66927c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chunks créés : 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_files = [\"cv_fr.pdf\", \"Valentin_Kocijancic_CV_2025 .pdf\", \"CV_2025-10-16_Axel_CLEMENT_v2.pdf\"]\n",
    "\n",
    "# chargement pdf\n",
    "documents = []\n",
    "for file in pdf_files:\n",
    "    loader = PyPDFLoader(file)\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n",
    "\n",
    "# chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # taille des chunks\n",
    "    chunk_overlap=200,    # chevauchement pour garder le contexte\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Nombre de chunks créés : {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dbf5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={'device': 'cpu'}  # 'cuda' si GPU\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4dabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21df1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    model=\"phi3\", #mistral\n",
    "    temperature=0.1,  # Pour des réponses plus factuelles\n",
    "    num_predict=256   # Limite la longueur des réponses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b495f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Tu es un assistant intelligent spécialisé dans l'analyse de CV pour les recruteurs.\n",
    "Tu dois répondre **en français** de manière claire, concise et professionnelle.\n",
    "\n",
    "Tu disposes des informations suivantes issues d'une base de CV :\n",
    "{context}\n",
    "\n",
    "Consignes :\n",
    "- Utilise uniquement les informations présentes dans le contexte pour répondre.\n",
    "- Si la réponse n'est pas clairement indiquée, dis simplement : \"L'information n'est pas disponible dans les CV.\"\n",
    "- Si plusieurs candidats semblent correspondre, mentionne leurs **NOM ET PRÉNOM COMPLET** et explique brièvement pourquoi.\n",
    "- Si un candidat se démarque particulièrement, indique-le clairement en donnant son **NOM ET PRÉNOM COMPLET** et justifie ton choix.\n",
    "\n",
    "Question du recruteur : {question}\n",
    "\n",
    "Réponse :\n",
    "\"\"\"\n",
    "\n",
    "prompt_fr = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb762f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt_fr}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7855e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valentin Kocijancic est le candidat qui recherche un stage en finance, comme indiqué dans son CV sous l'objectif. Il souhaite appliquer ses compétences techniques et analytiques au sein d'une équipe dynamique et stimulante pour une période de quatre mois à partir du 13 avril 2026.\n"
     ]
    }
   ],
   "source": [
    "question = \"Quel candidat cherche un stage en finance ?\"\n",
    "response = qa_chain({\"query\" : question})\n",
    "print(response['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
